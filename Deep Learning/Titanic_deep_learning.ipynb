{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Challenge:\n",
    "\n",
    "    The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "    On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "    While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "    In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "| Variable | Definition                                   | Key                                              |\n",
    "|----------|----------------------------------------------|--------------------------------------------------|\n",
    "| survival | Survival                                     | 0 = No, 1 = Yes                                  |\n",
    "| pclass   | Ticket class                                 | 1 = 1st, 2 = 2nd, 3 = 3rd                        |\n",
    "| sex      | Sex                                          |                                                  |\n",
    "| Age      | Age in years                                 |                                                  |\n",
    "| sibsp    | # of siblings / spouses aboard   the Titanic |                                                  |\n",
    "| parch    | # of parents / children aboard   the Titanic |                                                  |\n",
    "| ticket   | Ticket number                                |                                                  |\n",
    "| fare     | Passenger fare                               |                                                  |\n",
    "| cabin    | Cabin number                                 |                                                  |\n",
    "| embarked | Port of Embarkation                          | C = Cherbourg, Q = Queenstown, S =   Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        pclass: A proxy for socio-economic status (SES)\n",
    "                                        1st = Upper\n",
    "                                        2nd = Middle\n",
    "                                        3rd = Lower\n",
    "\n",
    "                                        age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "                                        sibsp: The dataset defines family relations in this way...\n",
    "                                        Sibling = brother, sister, stepbrother, stepsister\n",
    "                                        Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "                                        parch: The dataset defines family relations in this way...\n",
    "                                        Parent = mother, father\n",
    "                                        Child = daughter, son, stepdaughter, stepson\n",
    "                                        Some children travelled only with a nanny, therefore parch=0 for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#DF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Meet and Greet Data\n",
    "\n",
    "    This is the meet and greet step. Get to know your data by first name and learn a little bit about it. What does it look like (datatype and values), what makes it tick (independent/feature variables(s)), what's its goals in life (dependent/target variable(s)). Think of it like a first date, before you jump in and start poking it in the bedroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Survived',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin    687\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum().sort_values(ascending = False).head(1) #drop this useless as shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Cabin',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = list(X[X.select_dtypes(include=['object']).columns])\n",
    "num = list(X[X.select_dtypes(exclude=['object']).columns])\n",
    "my_cols = cat + num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num),       \n",
    "        ('cat',cat_transformer,cat),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 1583)\n"
     ]
    }
   ],
   "source": [
    "X_prepared = preprocessor.fit_transform(X)\n",
    "\n",
    "print(X_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_prepared, y, test_size=0.20, train_size=0.80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (891, 12)\n",
      "X_train Shape: (712, 1583)\n",
      "y_train Shape: (712,)\n",
      "X_valid Shape: (179, 1583)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape: {}\".format(train.shape))\n",
    "print(\"X_train Shape: {}\".format(X_train.shape))\n",
    "print(\"y_train Shape: {}\".format(y_train.shape))\n",
    "print(\"X_valid Shape: {}\".format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_valid = np.asarray(y_valid).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Keras Deep Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(24, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(24, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/20\n",
      "712/712 [==============================] - 0s 638us/step - loss: 0.6712 - accuracy: 0.6517 - val_loss: 0.6480 - val_accuracy: 0.6983\n",
      "Epoch 2/20\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6089 - accuracy: 0.7374 - val_loss: 0.5850 - val_accuracy: 0.7263\n",
      "Epoch 3/20\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.5304 - accuracy: 0.7978 - val_loss: 0.5135 - val_accuracy: 0.7821\n",
      "Epoch 4/20\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.4563 - accuracy: 0.8343 - val_loss: 0.4615 - val_accuracy: 0.7989\n",
      "Epoch 5/20\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4008 - accuracy: 0.8483 - val_loss: 0.4295 - val_accuracy: 0.8101\n",
      "Epoch 6/20\n",
      "712/712 [==============================] - 0s 210us/step - loss: 0.3613 - accuracy: 0.8567 - val_loss: 0.4150 - val_accuracy: 0.8156\n",
      "Epoch 7/20\n",
      "712/712 [==============================] - 0s 218us/step - loss: 0.3249 - accuracy: 0.8722 - val_loss: 0.4031 - val_accuracy: 0.8045\n",
      "Epoch 8/20\n",
      "712/712 [==============================] - 0s 184us/step - loss: 0.2879 - accuracy: 0.8904 - val_loss: 0.3986 - val_accuracy: 0.8324\n",
      "Epoch 9/20\n",
      "712/712 [==============================] - 0s 230us/step - loss: 0.2457 - accuracy: 0.9171 - val_loss: 0.3884 - val_accuracy: 0.8156\n",
      "Epoch 10/20\n",
      "712/712 [==============================] - 0s 168us/step - loss: 0.1997 - accuracy: 0.9340 - val_loss: 0.3916 - val_accuracy: 0.8436\n",
      "Epoch 11/20\n",
      "712/712 [==============================] - 0s 207us/step - loss: 0.1502 - accuracy: 0.9508 - val_loss: 0.3906 - val_accuracy: 0.8268\n",
      "Epoch 12/20\n",
      "712/712 [==============================] - 0s 192us/step - loss: 0.1059 - accuracy: 0.9677 - val_loss: 0.3913 - val_accuracy: 0.8101\n",
      "Epoch 13/20\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.0677 - accuracy: 0.9860 - val_loss: 0.4092 - val_accuracy: 0.8156\n",
      "Epoch 14/20\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.0418 - accuracy: 0.9930 - val_loss: 0.4168 - val_accuracy: 0.8101\n",
      "Epoch 15/20\n",
      "712/712 [==============================] - 0s 191us/step - loss: 0.0258 - accuracy: 0.9986 - val_loss: 0.4804 - val_accuracy: 0.7542\n",
      "Epoch 16/20\n",
      "712/712 [==============================] - 0s 214us/step - loss: 0.0159 - accuracy: 0.9986 - val_loss: 0.4896 - val_accuracy: 0.7374\n",
      "Epoch 17/20\n",
      "712/712 [==============================] - 0s 178us/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.5393 - val_accuracy: 0.7039\n",
      "Epoch 18/20\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.7263\n",
      "Epoch 19/20\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.6872\n",
      "Epoch 20/20\n",
      "712/712 [==============================] - 0s 196us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.7486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15284946548>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffr\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_test_prepared = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = predictions > 0.5\n",
    "predictions_2 = predictions_2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'PassengerId': X_test.PassengerId,\n",
    "                       'Survived': predictions_2[:,0]})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
